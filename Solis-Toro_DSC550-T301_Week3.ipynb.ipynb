{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca5db20-76c8-450b-a2fd-4ef0e63b0cb2",
   "metadata": {},
   "source": [
    "# DSC550-T301 Data Mining\n",
    "\n",
    "## Week 3: 3.2 Exercise: Sentiment Analysis and Preprocessing Text / Daniel Solis Toro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb369fb-f1f6-4ce8-9a3d-cbd52ca2e2d4",
   "metadata": {},
   "source": [
    "### PART 1 — Using the TextBlob Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e6526-c0f9-416d-9d52-14b2479a981f",
   "metadata": {},
   "source": [
    "1. Import the movie review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d9c92a-f714-40e5-a586-9e091bbde58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Display dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7e775-9cbb-4881-ab03-9cbc1c190bc1",
   "metadata": {},
   "source": [
    "2. Count positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ecab3a1-3b2f-4e2c-b5fd-a2d3c654c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    12500\n",
       "0    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dbfff-ad0c-4a55-9c70-3fa7561d402b",
   "metadata": {},
   "source": [
    "3. Classify sentiment using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65d1b96-24c4-4eae-be7a-9aa8165ca573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Define a function to classify sentiment\n",
    "def textblob_sentiment(review):\n",
    "    blob = TextBlob(review)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    if polarity >= 0:\n",
    "        return 1   # positive\n",
    "    else:\n",
    "        return 0   # negative\n",
    "\n",
    "# Apply the function to all reviews\n",
    "df['tb_prediction'] = df['review'].apply(textblob_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f00fdd-50b2-42f4-9e0b-1b13859a3cf8",
   "metadata": {},
   "source": [
    "4. Check accuracy of TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb898ae5-b0d9-49f9-b3ef-cd88abb5ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68524"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import accuracy metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_tb = accuracy_score(df['sentiment'], df['tb_prediction'])\n",
    "accuracy_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf335be5-c7a6-4f3c-bdb4-3ec9a40302f8",
   "metadata": {},
   "source": [
    "### Is this better than random guessing?\n",
    "\n",
    "- Random guessing = 50% accuracy\n",
    "- TextBlob accuracy = 68.5%\n",
    "\n",
    "Yes, it’s better than random, but not great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f45a7b-56c0-4e93-ba1b-f86afe8587d1",
   "metadata": {},
   "source": [
    "### Extra Credit: VADER Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc5826b7-ceb9-4146-98d4-a0a43ac97fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import VADER\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Initialize analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create prediction function\n",
    "def vader_sentiment(review):\n",
    "    score = sia.polarity_scores(review)['compound']\n",
    "    \n",
    "    if score >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply and evaluate\n",
    "df['vader_prediction'] = df['review'].apply(vader_sentiment)\n",
    "\n",
    "accuracy_vader = accuracy_score(df['sentiment'], df['vader_prediction'])\n",
    "accuracy_vader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61319207-27ac-4493-9d9c-09f64f9f7339",
   "metadata": {},
   "source": [
    "### Is this better than random guessing?\n",
    "\n",
    "- Random guessing = 50% accuracy\n",
    "- VADER accuracy = 69.3%\n",
    "\n",
    "Yes, it’s better than random, but not great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce93ff-5b90-4fc4-8fc2-8e3f49f1616d",
   "metadata": {},
   "source": [
    "### PART 2 — Prepping Text for a Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b7d27-4ce0-437a-ad23-f37b322fcddd",
   "metadata": {},
   "source": [
    "1. Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "378ba345-fa45-4b22-a17e-970d99252bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ea477-5983-458f-b5c6-b74c92ad7d5a",
   "metadata": {},
   "source": [
    "2. Remove punctuation and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c4205e-5eda-40c2-8b8e-43619cef2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['clean_review'] = df['clean_review'].apply(\n",
    "    lambda x: re.sub(r'[^a-z\\s]', '', x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41f552-1320-42bd-afb4-f9e0dc0669b6",
   "metadata": {},
   "source": [
    "3. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3edb221d-418c-4f76-a7d0-7a6bcbccf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove them\n",
    "df['clean_review'] = df['clean_review'].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054a031-836c-47df-97c0-0a395d583e3e",
   "metadata": {},
   "source": [
    "4. Apply Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfde63fb-f581-41be-8213-eb6a24ba37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "df['stemmed_review'] = df['clean_review'].apply(\n",
    "    lambda x: \" \".join([ps.stem(word) for word in x.split()])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f49a89-3627-42d4-addf-adc7e427461f",
   "metadata": {},
   "source": [
    "5. Create a Bag-of-Words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0c26191-601b-409a-8621-b6c02448e96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 89468)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create BoW matrix\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(df['stemmed_review'])\n",
    "\n",
    "# Display dimensions\n",
    "bow_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2e1257-846c-4a16-b909-00cd1a1db900",
   "metadata": {},
   "source": [
    "6. Create a TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5f5d46-c1a5-48c5-9914-9673a691a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 89468)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['stemmed_review'])\n",
    "\n",
    "# Display dimensions\n",
    "tfidf_matrix.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
